---
layout: post
title: "NGNIX"
excerpt: "The kick-ass secure front-end web server proxy"
tags: [web, performance]
image:
# pic silver robot white skin handshake 1900x500
  feature: https://cloud.githubusercontent.com/assets/300046/14622149/306629f0-0585-11e6-961a-dc8f60dadbf6.jpg
  credit: 
  creditlink: 
comments: true
---
<i>{{ page.excerpt }}</i>

{% include _toc.html %}

This tutorial intends to show complete newbies how to setup and configure
NGINX (pronounced "engine-x"). Step by step.

Unlike other documents, this tutorial presents responses from commands.


## NGINX Market Share

"The NGINX Docker image is the number one downloaded application image on Docker Hub."

In the <a target="_blank" href="https://news.netcraft.com/archives/2016/10/21/october-2016-web-server-survey.html">
October, 2016 survey from Netcraft</a>,
NGINX (the green line) is shown to be gaining market share 
over time while others are declining:

![nginx market mil 2016-10-650x286-101kb](https://cloud.githubusercontent.com/assets/23315276/20150570/d5830a18-a673-11e6-96a1-c4594db998bc.jpg)
This is for the top million sites on the internet.

What's more, based on counts by Alexa, <a target="_blank" href="https://www.datanyze.com/market-share/load-balancers/nginx-vs-microsoftiis"> Datanyze</a> 
and W3Tech,
NGINX is more common with high-traffic sites:

![nginx mkt share 459x186-63kb](https://cloud.githubusercontent.com/assets/23315276/20176492/508331f2-a705-11e6-905c-afb8609596a8.jpg)

Unlike Apache, which spawns a new thread for each new connection,
the NGINX web server is designed to be efficient at responding to static requests.
This is because it uses an "event-driven" approach for high concurrency, 
high performance, with small, predictable usage of memory.

Among the <a target="_blank" href="https://https://w3techs.com/technologies/report/web_server/">
88 "others"</a> are <a target="_blank" href="https://www.lighttpd.net/">
LightTPD</a> (pronounced "lighty").
Google's <a target="_blank" href="https://opensource.googleblog.com/2016/01/seesaw-scalable-and-robust-load.html"> Seesaw load balancer</a>,
a fork of Apache.

Open-source products for ADC (Application Delivery Controllers)
include HAProxy, 
Varnish, 
Zen Load Balancer (from SofIntel IT Engineering SL) 

<a target="_blank" href="https://www.gartner.com/doc/reprints?id=1-3GI1LFF&ct=160831&st=sb">
Gartner's August 2016 Magic Quadrant for Application Delivery Controllers<br />
<img alt="nginx adc market 2016 650x650-61kb.png" src="https://cloud.githubusercontent.com/assets/23315276/20248679/3da87b16-a9a6-11e6-934b-0f795ea8bd5e.png"></a>
includes F5 which is what Gartner calls a "Mode 1".
"Mode 1" products focus on predictability
and stability with what can be identified by a process of analysis
vs. "Mode 2" focus on exploratory with being basic, low-cost, easy-to-acquire.


There is some skepticism about 
<a target="_blank" href="http://www.webperformance.com/load-testing/blog/2011/11/what-is-the-fastest-webserver/">
speed benchmarks</a> vs. Microsoft's IIS and Apache Tomcat.


### Load Balancing

The revolution of NGINX is that unlike Apache,
it doesn't just die when overwhelmed because it keeps servers from being
overwhelmed. NGINX servers notify others when it can handle more traffic,
and those sending traffic use a server's health-check status 
as the basis for sending load to the server.
This is called the "circuit breaker" design pattern.

The default configuration option for load balancing is round-robin allocation among servers specified. There is also ip_hash which persists sessions from the source IP
used to calcuate a random hash.

   <pre>
upstream backend {
    ip_hash
    server webserver01:80;
    server webserver02:80;
}   
   </pre>

There is also "least_conn" for least connections when serving the same content.

The Plus edition provides a list of servers shared among them.


### Reverse proxy

NGINX is a "reverse proxy".
A "proxy" describes someone or something acting on behalf of someone else.
A forward proxy hides the identities of clients(users) whereas<br />
a reverse proxy hides the identities of your servers.

Spammers need to use different end-points so that they can continue 
with alternate IPs as the IPs they use are blocked.

But it's more than just hiding. It's being granularity to control what servers get accessed
even though traffic comes in requesting another IP.

NGINX does all this to SMTP, POP3, IMAP, as well as web HTTP/HTTPS protocols.


### Level 7 cache

NGINX operates at "Layer 7" (of the ISO 7-layer model),
meaning the load balancer
examines the content of messages from applications
(URLs and cookies) to 
reuse existing connections kept alive and 
route traffic directly to a specific type of server.

Because NGINX can understand what is requested,
it can fulfill requests without going to application servers to generate web pages.


### A/B Testing

NGINX can thus route a percentage of traffic to alternate versions of content
in order to measure wether visitors respond differently.
This is called A/B testing, like you do at the eye doctor.

The server URL is varied by using a $servers variable
in configuration to distribute traffic:

   <pre>
split_clients "${remote_addr}AAA" <strong>$servers</strong> {
    95% backends;
    5% 192.168.56.1:80;
}
server {
    listen 80;
    location / {
       proxy_pass http://<strong>$servers</strong>;
  }
}
   </pre>

### App Version Migrations

Alternating traffic among servers is also handy for "blue/green" deployments
where a complete set of servers holds a new version.
This enables easy fall-back in case the new version has a problem.

NGINX can deliver a small percentage of traffic to the new version to test the waters.

To ensure that a session returns to the same server,
NGINX is configured to use the group specification in a cookie that 
NGINX adds to the HTTP header for clients to return:

   <pre>
map $cookie_group $group {
   ~(?P&LT;value>.+)$ $value;
   default backendDB; # the default upstream group.
}
server {
    listen 80;
    location / {
       add_header Set-Cookie "group=$group; path=/"
       proxy_pass http://$group;
  }
}
   </pre>


### Fabric Mesh

The Fabric mesh defined in the
<a target="_blank" href="https://www.nginx.com/blog/introducing-the-nginx-microservices-reference-architecture/">
NGINX Microservices Reference Architecture</a>

<hr />

## Websites by NGINX

   * <a target="_blank" href="https://github.com/nginxinc/">
   https://github.com/nginxinc</a> with<br />
   <a target="_blank" href="https://github.com/nginxinc/nginx-wiki">
   https://github.com/nginxinc/nginx-wiki</a> to power:
   * <a target="_blank" href="https://www.nginx.com/resources/wiki/">
   https://www.nginx.com/resources/wiki</a>
   * <a target="_blank" href="https://github.com/nginxinc/docker-formula">
   https://github.com/nginxinc/docker-formula</a><br />
   <a target="_blank" href="https://docs.saltstack.com/en/latest/topics/development/conventions/formulas.html">
   described in Saltstack</a>
   * <a target="_blank" href="https://github.com/nginxinc/ansible-nginx">
   https://github.com/nginxinc/ansible-nginx</a>
   * <a target="_blank" href="https://github.com/nginxinc/NGINX-Demos">
   https://github.com/nginxinc/NGINX-Demos</a>
   * <a target="_blank" href="https://trac.nginx.org/nginx?_ga=1.1494324.404039256.1478716863">
   Bug tracking</a>
   * NGINX source is kept in Mercurial repositories.


## Wide Linux OS support

NGINX runs on a multitude of operating systems.


There are 
<a target="_blank" href="https://www.nginx.com/resources/admin-guide/installing-nginx-plus/">
different commands for different versions of different flavors of Linux</a>.

* RHEL, CentOS, Oracle Linux and Amazon Linux

   * RHEL5, CentOS5 or Oracle Linux5, install OpenSSL:
   * RHEL6, RHEL7, CentOS6, CentOS7, Oracle Linux6, Oracle Linux7, and Amazon Linux install ca-certificates
   <br /><br />

* Debian 7 (Wheezy), Debian 8 (Jessie), 
   Ubuntu 12.04 (Precise), Ubuntu 14.04 (Trusty), 
   Ubuntu 16.04 (Xenial), Ubuntu 16.10 (Yakkety)

   apt-get 

* SLES (SUSE Linux Enterprise Server) 12 & 12 SP1

* FreeBSD  9.3, 10.1+ and 11.0

   ports

* Windows (as of NGINX 0.8.50) ???

See https://cs.nginx.com/repo_setup

Let's start with:

## Install manually locally on a Mac 

0. In a Terminal shell window:

   <tt><strong>
   brew install nginx
   </strong></tt>

   The response (redacted):

   <pre>
==> Installing dependencies for nginx: openssl@1.1
==> Installing nginx dependency: openssl@1.1
==> Caveats
A CA file has been bootstrapped using certificates from the system
keychain. To add additional certificates, place .pem files in
  /usr/local/etc/openssl@1.1/certs
&nbsp;
and run
  /usr/local/opt/openssl@1.1/bin/c_rehash
&nbsp;
This formula is keg-only, which means it was not symlinked into /usr/local.
&nbsp;
Apple has deprecated use of OpenSSL in favor of its own TLS and crypto libraries
&nbsp;
Generally there are no consequences of this for you. If you build your
own software and it requires this formula, you'll need to add to your
build variables:
&nbsp;
    LDFLAGS:  -L/usr/local/opt/openssl@1.1/lib
    CPPFLAGS: -I/usr/local/opt/openssl@1.1/include
    PKG_CONFIG_PATH: /usr/local/opt/openssl@1.1/lib/pkgconfig
&nbsp;
==> Summary
üç∫  /usr/local/Cellar/openssl@1.1/1.1.0b: 6,222 files, 15.3M
==> Installing nginx
==> Downloading https://homebrew.bintray.com/bottles/nginx-1.10.2_1.sierra.bottl
######################################################################## 100.0%
==> Pouring nginx-1.10.2_1.sierra.bottle.tar.gz
==> Caveats
Docroot is: /usr/local/var/www
&nbsp;
The default port has been set in /usr/local/etc/nginx/nginx.conf to 8080 so that
nginx can run without sudo.
&nbsp;
nginx will load all files in <strong>/usr/local/etc/nginx/servers/</strong>.
&nbsp;
To have launchd start nginx now and restart at login:
  brew services start nginx
Or, if you don't want/need a background service you can just run:
  nginx
==> Summary
üç∫  /usr/local/Cellar/nginx/1.10.2_1: 8 files, 979.5K   
   </pre>

   ### OpenSSL Dependency

   PROTIP: NGINX negotiates HTTPS traffic so downstream servers can use plain HTTP traffic without the encryption overhead. This is important for companies who want to keep TLS/SSL certificate handling on only one set of servers by a small set of people.

0. Verify install of OpenSSL:

   <tt><strong>
   openssl version
   </strong></tt>

   The response:

   <pre>
   OpenSSL 1.0.2g  1 Mar 2016
   </pre>

   The previous version with the Heartbleed vulnerability was 1.0.1p
   (which was why it was a prime target for hackers).

   There has been a shift in security:

   For newer RHEL6, RHEL7, CentOS6, CentOS7, Oracle Linux6, Oracle Linux7, and Amazon Linux,
   install ca-certificates:

   <tt><strong>
   sudo yum install ca-certificates
   </strong></tt>

   For older RHEL5, CentOS5, or Oracle Linux5, install OpenSSL:

   sudo yum install openssl


   ### Bring it up 

0. Run:

   <tt><strong>
   nginx
   </strong></tt>

   NOTE: The program is in /usr/bin by default.

   The prompt returns because a background process was started.

   <a target="_blank" href="https://www.nginx.com/resources/wiki/start/topics/tutorials/commandline/">
   
   Notice it runs under the bash shell, not as a separate process.

0. Switch to an internet browser to view:

   <tt><strong>
   localhost:8080
   </strong></tt>

   <a name="WelcomePage"></a>

   The response is the NGINX Welcome page:

   <hr />
   ![nginx hello 527x208-100kb](https://cloud.githubusercontent.com/assets/14143059/19688633/c4957de6-9a87-11e6-96e7-d483e8d4ef17.jpg)
   <hr />

   <a target="_blank" href="https://www.nginx.com/blog/welcome-to-nginx-on-my-favourite-website/">
   If you see this on other sites</a>

   * <a target="_blank" href="http://nginx.org/">
   http://nginx.org</a> lists releases of open source editions.
   * <a target="_blank" href="http://nginx.com/">
   http://nginx.com</a> is a modern sales page for NGINX Plus.
   <br /><br />

   <a target="_blank" href="https://www.nginx.com/products/feature-matrix/">
   The difference between free and Plus licensed offerings</a>
   include load balancing, session persistence, cache, 
   additional health checks, live streaming,
   support for GeoIP2, <a href="#nginScript">nginScript</a>.


   <a name="LicenseCerts"></a>

   ### Pro Trial Keys

0. Click on "Free Trial" and get an email from evaluations@nginx.com.
0. In your email, click the link to accept the agreement:

   https://cs.nginx.com/t/.../accept

0. Check the "I accept" and click Submit.

   "Trial successfully activated" appears.

0. Click "Certificate" to download the <strong>nginx-repo.crt</strong> (X.509) file.

   NOTE: ".crt" means certificate. Alt-click on the file on a Mac Keychain Access.
   Open the file using a text editor to see it starts with:

   <pre>
   -----BEGIN CERTIFICATE-----
   </pre>

0. Click "Private Key" to download the <strong>nginx-repo.key</strong> file.

   NOTE: On a Mac, the ".key" file is also used for Keynote files. 
   But open this file in a text editor:

   <pre>
   -----BEGIN PRIVATE KEY-----
   </pre>

0. Click the green "instructions" link for a web page containing a "one-time" license key 
   embedded within code you execute on the one server you're setting up:

   <pre>
   wget https://cs.nginx.com/static/install-nginx && sudo chmod +x install-nginx
   sudo ./install-nginx 3c3acc3abea9795eda91ac3956a96c30
   </pre>

   For multiple servers, you have to email evaluations@nginx.com.

   Skip to <a href="#Configure">configuration after install</a>.


## Run using Vagrant and Docker

### Install Vagrant and Docker

0. Install Vagrant for your version of Mac, Windows, Debian, Centos.

   vagrant_1.8.7.dmg

   PROTIP: Vagrant is used to set-up virtual machines by importaing
   pre-made images called "boxes" containing settings.

   Think of it as a scripting engine for VirtualBox,
   a "free, cross-platform consumer virtualization product".

0. Install Virtualbox.

   The default provider is VirtualBox versions 4.0, 4.1, 4.2, 4.3 only.
   <a target="_blank" href="https://www.vagrantup.com/docs/virtualbox/">
   More recent ones are 5.0.x and 5.1.x</a>.

   Download from 
   https://www.virtualbox.org/wiki/Downloads
   file VirtualBox-5.1.8-111374-OSX.dmg

   If you do not want to use VirtualBox,
   other providers are listed at:<br />
   https://docs.vagrantup.com/v2/providers/

   http://www.vagrantbox.es/

   PROTIP: Vagrant is a product from <a target="_blank" href="https://www.hashicorp.com/">
   Hashicorp.com</a> which also makes
   Atlas (the enterprise edition) to 
   <a target="_blank" href="https://www.hashicorp.com/#open-source-tools">
   open-source</a>
   Packer, Terraform, Vault, Nomad, and Consul.

   ### Install providers

0. Install provider for vagrant to start VM's.

   ???

0. Clone demo files to your local machine:

   ```
   git clone git@github.com:nginxinc/NGINX-Demos.git
   cd NGINX-Demos
   ```
 
0. Be at the hello folder:

   ```
   cd nginx-hello
    ```
 
0. Download nginx-repo.crt and nginx-repo.key files from
   <a target="_blank" href="https://cs.nginx.com/?_ga=1.103866629.404039256.1478716863">
   NGINX Customer Portal</a>.

0. Copy <a href="#LicenseCerts">license certs</a> 
   nginx-repo.key and 
   nginx-repo.crt files 
   from your account to the target server:
   
   ```
   TARGET="~/NGINX-Demos/autoscaling-demo/ansible/files/"
   sudo cp nginx-repo.key $TARGET
   sudo cp nginx-repo.crt $TARGET
   ```

   NOTE: In Linux the folder is `/etc/ssl/nginx`.

0. Initialize:

   <tt><strong>
   vagrant init hashicorp/precise64
   </strong></tt>

   The response:

   <pre>
A `Vagrantfile` has been placed in this directory. You are now
ready to `vagrant up` your first virtual environment! Please read
the comments in the Vagrantfile as well as documentation on
`vagrantup.com` for more information on using Vagrant.
   </pre>   

0. Bring up the VM:

   <tt><strong>
   vagrant up --provider=PROVIDER
   </strong></tt>

   NOTE: A single vagrant up command creates and starts up all VMs, 
   and distributes the templates and other files to them.

   It it's not done already, this command also creates the box from your specified base box
   after fetching it from its URL and download it to your machine
   (no downloading ISO, unzip, etc.):

   <pre>
==>  Provider 'virtualbox' not found. We'll automatically install it now...
     The installation process will start below. Human interaction may be
     required at some points. If you're uncomfortable with automatically
     installing this provider, you can safely Ctrl-C this process and install
     it manually.
==>  Downloading VirtualBox 5.0.10...
     This may not be the latest version of VirtualBox, but it is a version
     that is known to work well. Over time, we'll update the version that
     is installed.
==>  Installing VirtualBox. This will take a few minutes...
     You may be asked for your administrator password during this time.
     If you're uncomfortable entering your password here, please install
     VirtualBox manually.
Password: _
   </pre>

0. Type in your administrator password.
   Then wait for response:

   ==>  VirtualBox has successfully been installed!





## Run simple Hello world

   Have NGINX run a webserver in a Docker container to
   serve a simple index.html page containing the container's 
   hostname, IP address, and port.

0. First, [setup Docker according to my instructions](/docker-setup/).
   sudo systemctl status docker.service

0. Run the <a target="_blank" href="https://hub.docker.com/r/nginxdemos/hello/">
   "hello" image stored by user <strong>nginxdemos</strong> in Docker Hub</a>:

   <tt><strong>
   docker run -P -d nginxdemos/hello
   </strong></tt>

   If it has not been loaded yet, you'll see something like:

   <pre>
Unable to find image 'nginxdemos/hello:latest' locally
latest: Pulling from nginxdemos/hello
3690ec4760f9: Pull complete 
e13b170882f4: Downloading 5.176 MB/14.47 MB
6a5d3c1484a0: Download complete 
   </pre>   

   After download completes, you should see:

   <pre>
Digest: sha256:d2ea7dfdd199e04bea10ca6a807f822b242552ff5306871cc588382fe396c45d
Status: Downloaded newer image for nginxdemos/hello:latest
2289fc019878fd78031ae83e55c1187ef5678331e3ebe2708a4d42b400ec780e
   </pre>

0. In an internet browser, get to:

   <pre>
   http://127.0.0.1:8080
   </pre>

   The <a href="#WelcomePage">
   NGINX Welcome screen</a> should appear.

0. Use a text editor to see the Docker file
   https://github.com/nginxinc/NGINX-Demos/tree/master/nginx-hello
   nginx-hello</a> 

   <pre>
FROM nginx:mainline-alpine
RUN rm /etc/nginx/conf.d/*
ADD hello.conf /etc/nginx/conf.d/
ADD index.html /usr/share/nginx/html/
   </pre>


0. The <a target="_blank" href="https://github.com/nginxinc/NGINX-Demos/blob/master/nginx-hello/hello.conf">
   NGINX conf file</a>   

   <pre>
server {
    listen 80;
&nbsp;
    root /usr/share/nginx/html;
    try_files /index.html =404;
&nbsp;
    expires -1;
&nbsp;
    sub_filter_once off;
    sub_filter 'server_hostname' '$hostname';
    sub_filter 'server_address' '$server_addr:$server_port';
    sub_filter 'server_url' '$request_uri';
    sub_filter 'remote_addr' '$remote_addr:$remote_port';
    sub_filter 'server_date' '$time_local';
    sub_filter 'client_browser' '$http_user_agent';
    sub_filter 'request_id' '$request_id';
}
   </pre>

   NGINX Plus
   exposes configuration settings with a GUI,
   much like what F5 does with their dashboard.


<a name="Configure"></a>

## Edit NGINX Configuration

0. Verify if configuration is ok (without killing the running instance),
   and print info, warnings, and error messages.

   <tt><strong>
   nginx -t
   </strong></tt>

   The response if good:

   <pre>
nginx: the configuration file <strong>/usr/local/etc/nginx/nginx.conf</strong> syntax is ok
nginx: configuration file /usr/local/etc/nginx/nginx.conf test is successful
   </pre>
   <br />

   PROTIP: This command displays the location of the conf (configuration) file.

0. Highlight the path and copy it for use in commands to edit the conf file.

   <strong>/usr/local/etc/nginx/nginx.conf</strong>

0. Use a text editor to edit the configuration file:

   <tt><strong>
   atom /usr/local/etc/nginx/nginx.conf
   </strong></tt>

   <pre>
#user  nobody;
worker_processes  1;
#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;
#pid        logs/nginx.pid;
events {
    worker_connections  1024;
}
http {
    include       mime.types;
    default_type  application/octet-stream;
    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
    #                  '$status $body_bytes_sent "$http_referer" '
    #                  '"$http_user_agent" "$http_x_forwarded_for"';
    #access_log  logs/access.log  main;
    sendfile        on;
    #tcp_nopush     on;
    #keepalive_timeout  0;
    keepalive_timeout  65;
    #gzip  on;
    server {
        listen       8080;
        server_name  localhost;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            root   html;
            index  index.html index.htm;
        }
        #error_page  404              /404.html;
        # redirect server error pages to the static page /50x.html
        #
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
        # proxy the PHP scripts to Apache listening on 127.0.0.1:80
        #
        #location ~ \.php$ {
        #    proxy_pass   http://127.0.0.1;
        #}
        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
        #
        #location ~ \.php$ {
        #    root           html;
        #    fastcgi_pass   127.0.0.1:9000;
        #    fastcgi_index  index.php;
        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
        #    include        fastcgi_params;
        #}
        # deny access to .htaccess files, if Apache's document root
        # concurs with nginx's one
        #
        #location ~ /\.ht {
        #    deny  all;
        #}
    }
    # another virtual host using mix of IP-, name-, and port-based configuration
    #
    #server {
    #    listen       8000;
    #    listen       somename:8080;
    #    server_name  somename  alias  another.alias;
    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}
    # HTTPS server
    #
    #server {
    #    listen       443 ssl;
    #    server_name  localhost;
    #    ssl_certificate      cert.pem;
    #    ssl_certificate_key  cert.key;
    #    ssl_session_cache    shared:SSL:1m;
    #    ssl_session_timeout  5m;
    #    ssl_ciphers  HIGH:!aNULL:!MD5;
    #    ssl_prefer_server_ciphers  on;
    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}
    include servers/*;
}
   </pre>

   ### Changes


   ### Reload Configuration

0. After editing config, do a hot reload without downtime:
   disconnecting users:

   <tt><strong>
   service nginx reload
   </strong></tt>

   or

   <tt><strong>
   /etc/init.d/nginx reload
   </strong></tt>

   These send a SIGHUP signal to the nginx master process. 

   See http://nginx.org/en/docs/control.html


<a name="nginScript"></a>

## nginScript

Embed snippets of JavaScript in NGINX configuration,
to dynamically control the internal operation of NGINX precisely for each request.

This is a new Pro feature.

See https://www.nginx.com/resources/wiki/nginScript/


   <a name="Restart"></a>

## Stop and Restart

   https://www.nginx.com/resources/wiki/start/topics/tutorials/commandline/

   nginx -s reload


## Install on Linux

This is for reals with real servers.

<br /><br />

0. In a shell:

   <tt><strong>
   sudo apt-get update<br />
   sudo apt-get install nginx
   </strong></tt>


   <a target="_blank" href="https://www.nginx.com/resources/wiki/start/topics/tutorials/commandline/">
   
   ## Configure HTTPS

0. Create a directory to hold SSL/TLS keys:

   <pre><strong>
   sudo mkdir /etc/ssl/nginx
   cd /etc/ssl/nginx
   </strong></pre>


0. Ansible

   https://github.com/nginxinc/NGINX-Demos/tree/master/ansible


0. View the process ID of the master process written to the file:

   <tt><strong>
   cat /usr/local/nginx/logs/nginx.pid
   </strong></tt>
   

## Examine config #

0. List the files installed (from path output during Mac installation above):

   <tt><strong>
   ls /usr/local/etc/nginx/servers/
   </strong></tt>

   The response:

   <pre>
conf.d          mime.types        proxy_params    uwsgi_params
fastcgi_params  naxsi_core.rules  scgi_params     win-utf
koi-utf         naxsi.rules       sites-available
koi-win         nginx.conf        sites-enabled
   </pre>   

   On Linux:

   <pre>
   cd /etc/nginx/
   </pre>

   ### Examine config #

0. How mancy cores does your machine have?

   The cross-platform approach: 

   <pre><strong>   
   python -c 'import multiprocessing as mp; print(mp.cpu_count())'
   </strong></pre>

   On a Mac, use a utility from Apple:

   <tt><strong>
   sysctl -n hw.ncpu<br />
   sysctl hw.physicalcpu
   </strong></tt>

   The response is 8 <strong>logical</strong> cores
   from 2 physical cores from  system_profiler SPHardwareDataType .


   On Linux:

   <tt><strong>
   grep ^processor /proc/cpuinfo | wc -l
   </strong></tt>


## Configuration #

0. Examine the default configuration file 
   (substituting vim with atom or whatever text editor you prefer):

   <tt><strong>
   vim nginx.conf
   </strong></tt>

   Directives are defined in <br />
   <a target="_blank" href="http://nginx.org/en/docs/http/ngx_http_core_module.html">
   http://nginx.org/en/docs/http/ngx_http_core_module.html</a>

   ### Processes 

   For `worker_processes` specify one for each core on the machine being used.
   The default is a 4-core server.

   Each worker can handle thousands of concurrent connections
   asynchronously in a single thread.

   ### Connections

   The `worker_connections` default of 768 needs to be adjusted based on 
   what a server can handle based on the set of applications running on it.

   Since separate connections are used for incoming and outgoing,
   each end-user browser uses at least two connections.

0. Check your machine's connection limit:

   <tt><strong>
   ulimit -n
   </strong></tt>

   On my Mac, it's 256.

   On a small Linux droplet (512 MB), it may be 1024.

   Have a script do this upon start-up.

   ### Keepalive

   The `keepalive_timeout` default of 65 also needs to be adjusted based on 
   the remoteness of users from servers.
   For example, if the majority of users are in South Africa are accessing a server
   in Menlo Park, then you'll likely need a longer one.

   ### Buffer sizes #

   If you encounter a HTTP 413 "Rquest Entity Too Large" error,
   adjust these:

   `client_body_buffer_size 10K;`
   defines the max POST actions received (typically HTML FORMs).

   `client_max_body_size 8m;`

   `client_header_buffer_size 1K;`
   usually need to be increased if the header contains a lot of info.
   64K is a good size. 

   The companion is to up to `4 64K`
   `large_client_header_buffers 2 1K;`


   ### Gzip  

   If `gzip_comp_level` is too high, the server wastes CPU cycles.

   <pre>
   location /api {
     expires 10m;
   }
   </pre>


   ### Chef replace #

   Chef knows to look in the file and replaces values from a file such as this:

   <pre>
node.set[‚Äônginx‚Äô][‚Äòworker_connections‚Äô] = 8192
node.set[‚Äônginx‚Äô][‚Äòworker_rlimit_nofile‚Äô] = 32768
node.set[‚Äônginx‚Äô][‚Äòevent‚Äô] = ‚Äòepoll'
node.set[‚Äônginx‚Äô][‚Äòclient_max_body_size‚Äô] = ‚Äò4m'
   </pre>


### sites-enabled defaults #

0. Define a <strong>defaults</strong> file within site-enabled folder:

   <tt><strong>
   cd sites-enabled<br />
   sudo vim defaults
   </strong></tt>

   Define nodes (backend), all listening on port 80:

   <pre>
upstream backend {
  server 22.22.22.2:3000;
#  server 22.22.22.3:3000;
# server 22.22.22.4:3000;
}
server {
   listen 80;
&nbsp;
   location / {
     proxy_pass https://backend;
   }
&nbsp;
  # Cache static assets 7 days (168/24):
  location ~* \.(ico|gif|jpe?g|png|mp4|mp3|svg|css|js)$ {
    exprires 168h;
  }
}
   </pre>

   The `http://backend` forward incoming requests among ip addresses 
   defined under `backend` (app container). 
   This load balances.

   NOTE: HTTP 304 is issued for requests proxied.


   ### Reconfig

   On-the-fly reconfiguration (provided by the Plus edition) by a URL such as:

<pre>
curl 'http://host/upstream_conf?upstram=backend&id=3&down=1'
</pre>




   ### With Docker:

   Use a resolver server:

   <pre>
server {
   listen 80;
&nbsp;
   resolver 127.0.0.11 valid=5s;
   set $upstream http://project;
   location / {
     proxy_pass $upstream;
   }
&nbsp;
  # Cache static assets 7 days (168/24):
  location ~* \.(ico|gif|jpe?g|png|mp4|mp3|svg|css|js)$ {
    exprires 168h;
  }
}
   </pre>

   Remember for 5 seconds.

   ### Which ports are listening?

   <tt><strong>
   lsof -nP +c 15 | grep LISTEN
   </strong></tt>

   The response is long lines.
   So drag your Terminal window wider to remove word-wrap.


## Multiple upstreams & rewrite rules

   <a target="_blank" href="https://www.youtube.com/watch?v=A2NOziRYh7U">
   Load Balancing a Dynamic Infrastructure with NGINX, Chef, and Consul</a>
   by Kevin Reedy (of Belly) presented this at ngix.conf 2014:

   Using Chef's templating:

   <pre>
upstream api {
  least_conn;
  &LT;$ @servers.each do |server\ %>
  server &LT;%= server['ipaddress %>:8080;
  &LT;% end %>
}
upstream homepage {
  least_conn;
  server 10.0.0.201:8080;
  server 10.0.0.202:8080;
}
server {
  listen: 80;
  server_name api.bellycard.com;
  location / {
    proxy_pass http://api;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_add;
    proxy_set_header X-Forwarded-Proto https;
  }
}
server {
  listen: 80;
  server_name www.bellycard.com;
  location / {
    proxy_pass http://homepage;
  }
  location /api {
    proxy_pass http://api;
  }
}
   </pre>

   ### SSL/TLS

   See https://bjornjohansen.no/letsencrypt-nginx

   <pre>
# Usign a certificate created for multiple domains:
&nbsp;
   # Certificate chain: 
   ssl_certificate /usr/local/etc/openssl@1.1/certs/signed_cert_plus_intermediates.crt;
&nbsp;
   # Private key:
   ssl_certificate_key /path/to/private.key;
&nbsp;
   # 50 megabyte Session caching for faster connections from existing clients:
   ssl_session_timeout 1d;
   ssl_session_cache shared:SSL:50m;
&nbsp;
   ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
   ssl_ciphers EECHD+CHACHA20:EECDH+AES128:RSA+AES128:EECD+AES256:RSA+AES256:EECD+3DES:RSA+3DES:!MD5;
   ssl_prefer_server_ciphers on;
&nbsp;
   # HSTS (Hypertext Strick Transport Security) to always reach using HTTPS 
   # which prevents hijacking of HTTP for 6 months:
   # (requires ngx_http_headers_module)
   # add_header Strict-Transport-Security max-age=15768000;
&nbsp;
   # Session tickets for Chrome & Firefox users:
   # Generate a random 48-byte file.
&nbsp;
   # Fetch OCSP (Online Certificate Status Protocol) records from 
   # URL in ssl_certs and to pre-fetch OSCP response, to save a round trip
   # (30A% faster) by providing file from CA:
   ssl_stapling on;
   ssl_stapling_verify on;
   ssl_trusted_certificate /usr/local/etc/openssl@1.1/certs/root_CA_cert_plus_intermediates.crt;
&nbsp;
server {
   listen 443 ssl;
   server_name   www.example.com;
...
}
server {
   listen 443 ssl;
   server_name   www.example.org;
}
...
   </pre>

   ### Back-end encryption #

   <pre>
http {
  server {
    proxy_ssl_protocols TLSv1 TLSv1.1 TLSv1.2;

    proxy_ssl_ciphers EECHD+CHACHA20:EECDH+AES128:RSA+AES128:EECD+AES256:RSA+AES256:EECD+3DES:RSA+3DES:!MD5;

    # Internal or public: On Ubuntu:
    proxy_ssl_trusted_certificate /etc/ssl/certs/trusted_ca_cert.crt;

    proxy_ssl_verify on;
    proxy_ssl_verify_depth 2;
    proxy_ssl_session_reuse on;
...
   </pre>


## Start service #

0. Define a <strong>defaults</strong> file within site-enabled folder:

   <tt><strong>
   sudo service nginx start
   </strong></tt>


   ### Stress test #

0. Use Apache bench to run 1000 requests 40 concurrent (at a time):

   <tt><strong>
   ab -c 40 -n 1000 http://22.22.22.4/
   </strong></tt>

   1000 / 40 = 25 / .5 seconds = 5 seconds to complete benchmark run.


   ### Add servers 

0. PROTIP: When more are needed, edit the file and reload.

   <tt><strong>
   sudo service nginx reload
   </strong></tt>


## Docker

<a target="_blank" href="https://www.youtube.com/watch?v=HJ9bECmuwKo">
   https://www.youtube.com/watch?v=HJ9bECmuwKo</a>
   July 2016
   by Quentin Stafford-Fraser
   uses a dockerfile:

   <pre>
   FROM nginx:alpine
   COPY index.html /usr/share/nginx/html
   </pre>

The docker-compose.yml file:

   <pre>
version: '2'
services:
  app:
    build: app
  proxy:
    build: proxy
    ports:
    - "80:80"
   </pre>

   Version 2 means Docker uses its DNS server so a link is not needed here.

   The build is to the proxy directory.

   "80:80" binds from local host to port on proxy.

0. Build

   <tt><strong>
   docker-compose build
   </strong></tt>

0. Up

   <tt><strong>
   docker-compose up
   </strong></tt>

0. Verify

   <tt><strong>
   docker ps
   </strong></tt>

0. View in proxy:

   <tt><strong>
   docker-compose exec proxy sh
   </strong></tt>

   List IPs addressed by proxy:

   <tt><strong>
   nslookup app
   </strong></tt>

0. Scale

   <tt><strong>
   docker-compose scale -h
   </strong></tt>

   To fire up 4 instances of app services and 2 workers:

   <tt><strong>
   docker-compose scale app=4 worker=2
   </strong></tt>

<a target="_blank" href="https://www.youtube.com/watch?v=6uucWLPcAPY">
Interconnecting containers at scale with NGINX</a>
by Sarah Novotny, Technical Evangelist, NGINX

0. To create traffic on a command line:

   <tt><strong>
   curl -k -i https://localhost:8081
   </strong></tt>



## Verify security

When deployed to a public site:

   https://ssllabs.com

See https://blog.qualys.com/ssllabs/2013/06/25/ssl-labs-deploying-forward-secrecy

## Videos #

<a target="_blank" href="https://www.youtube.com/channel/UCy6gt7XvGJ3AGpSon2pS4nQ">
  On the NGINX YouTube channel</a>:


* <a target="_blank" href="https://www.youtube.com/watch?v=dsTub1_4Upg">
   NGINX + https 101 The Basics & Getting Started</a>
   at nginx.conf 2015 Sep 22-24
   by Nick Sullivan @grittygrease
   from Cloudflare

Others:

* <a target="_blank" href="https://devops.profitbricks.com/tutorials/configure-nginx-as-a-reverse-proxy-for-apache-on-ubuntu-1604/">
   Configure Nginx as a Reverse Proxy for Apache on Ubuntu 16.04
   at ProfitBricks</a>

* <a target="_blank" href="https://www.youtube.com/watch?v=6oXn5blsCWM">
   What is Nginx | Ngnix basic Video Tutorial | DevOps Tutorial For Beginners | Edureka</a>

* https://www.youtube.com/watch?v=YHcRzDKo6qU
   NGINX -- The Web Server You Might Actually Like
   by International PHP Conference
