---
layout: post
title: "RDP (Remote Desktop Protocol) to Windows machines"
excerpt: "Connect to Windows server in AWS or any cloud"
tags: [apple, mac, setup, RDP, cloud]
filename: "2107-08-30-analysis.md"
image:
# feature: pic gray apple logo 1900x500.jpg
  feature: https://cloud.githubusercontent.com/assets/300046/14625335/52952250-059f-11e6-84c8-5ae2d289c486.jpg
  credit: Wonderful Engineering
  creditlink: http://cdn.wonderfulengineering.com/wp-content/uploads/2013/11/apple-wallpaper-3.jpg
comments: true
---
<i>{{ page.excerpt }}</i>
<hr />

{% include _toc.html %}

This repository is a package of software to enable processing and visualization of data collected from various sources.

This effort is necessary for data related especially to load/stress testing because current vendors today provide visualization of only individuals metric at a time for individual runs, without additional context.

The context needed are visualizations across many dimensions to identify:

   * Creeping increases in response times for the same metric <strong>over several versions</strong>.

   ![viz-pt-creeping-650x285-34125](https://user-images.githubusercontent.com/300046/30036662-8fa637d2-9172-11e7-8286-6e0fa3332fe0.jpg)

   * Sudden change in memory per user within a specific enviornment, when compared against the same metric <strong>across environments</strong> from dev to production.

   ![viz-pt-env-diff-650x270-79779](https://user-images.githubusercontent.com/300046/30036768-575287fe-9173-11e7-8b2c-12eb72ada985.jpg)

   * Differences integrating data gathered from <strong>desparete sources</strong> (CA-APM GC metrics, LoadRunner Transactions Per Second).

   * Differences between similar data gathered from multiple tools (from <strong>multiple vendors</strong>), such as LoadRunner, Gatling, JMeter, Selenium, etc. so that they can be evaluated for <strong>consistency</strong>.

More importantly, a different approach is needed than what current vendors provide in terms of alert triggers:  Instead of requiring people to diligently pour through all the various graphs across runs in various enviornments for every release, this effort aims for people to receive alerts after <strong>intelligent software identify trends and anomalies</strong> after assimilating data from various runs and sources, around the clock.

### Peak Summary Metrics

Additionally, we want a way to use what I call "peak summary metrics", such as the average response time during the "steady state period" between ramp-up and ramp-down.

   ![lr-response-time-sustained-991x395-173338](https://user-images.githubusercontent.com/300046/30036387-209157d4-9170-11e7-8503-e9c5c5b445b4.jpg)

When the number summarizes the graph as a number, we can then combine it with the "sustained hits per second" metric captured and averaged during the same period. 

This summarization enables visualization to reveal tends and anomalies over several runs in the association between average response time and sustained hits per second.


## Flow

This page is about a system program I am writing to parse HTML pages and write it into a database so that run results can be analyzed and visualized "better".

Proactive


## Python

I chose Python because ...

http://docs.python-guide.org/en/latest/scenarios/scrape/