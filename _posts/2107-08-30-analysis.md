---
layout: post
title: "Analysis"
excerpt: "Analyze and visualize across multiple dimensions, automatically"
tags: [apple, mac, setup, RDP, cloud]
filename: "2107-08-30-analysis.md"
image:
  feature: https://cloud.githubusercontent.com/assets/300046/14583248/4b20c578-03d9-11e6-8f7a-c860b666bc73.jpg
  credit: Wall Street Journal
  creditlink: http://graphics.wsj.com/job-market-tracker/
comments: true
---
<i>{{ page.excerpt }}</i>
<hr />

{% include _toc.html %}

This repository is a package of software to enable processing, alerting, and visualization of data collected from various sources.

This effort is necessary for data related especially to load/stress testing because current solutions provide visualization of only individuals metrics for individual runs, without understanding additional context.

The context needed span across many dimensions to identify:

   * Creeping increases in response times for the same metric <strong>over several versions</strong> of the application.

   ![viz-pt-creeping-650x285-34125](https://user-images.githubusercontent.com/300046/30036662-8fa637d2-9172-11e7-8286-6e0fa3332fe0.jpg)

   * Sudden change in memory per user (or other ratios) within a specific enviornment, when compared against the same metric <strong>across environments</strong> from dev to production.

   ![viz-pt-env-diff-650x270-79779](https://user-images.githubusercontent.com/300046/30036768-575287fe-9173-11e7-8b2c-12eb72ada985.jpg)

   * Differences integrating data gathered from <strong>difference sources</strong> (CA-APM GC metrics, LoadRunner Transactions Per Second).

   * Differences between similar data gathered from multiple tools (from <strong>multiple vendors</strong>), such as LoadRunner, Gatling, JMeter, Selenium, etc. so that they can be evaluated for <strong>consistency</strong>.

More importantly, a different approach is needed than what current vendors provide in terms of alert triggers:  Instead of requiring people to diligently pour through all the various graphs across runs in various enviornments for every release, this effort aims for people to receive alerts after <strong>intelligent software identify trends and anomalies</strong> after assimilating data from various runs and sources, around the clock.


### Peak Summary Metrics

Additionally, we want a way to use what I call "peak summary metrics", such as the average response time during the "steady state period" between ramp-up and ramp-down.

   ![lr-response-time-sustained-991x395-173338](https://user-images.githubusercontent.com/300046/30036387-209157d4-9170-11e7-8503-e9c5c5b445b4.jpg)

   In the above example, Average Response Time averages 110 for the transaction shown by the top line (in purple), 40 in a lower line, etc.

When the number summarizes the graph as a number, we can then combine it with the "sustained hits per second" metric captured and averaged during the same period. 

This summarization enables visualization to reveal tends and anomalies over several runs in the association between average response time and sustained hits per second.


## Data Flow

This page is about a system program I am writing to parse HTML pages and write it into a database so that run results can be analyzed and visualized "better".

Proactive


## Python

I chose Python because ...

http://docs.python-guide.org/en/latest/scenarios/scrape/